#!/usr/bin/env python3
"""
ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ•´åˆæ€§æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã‚’ç¢ºèªã—ã¾ã™ï¼š
1. ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å­˜åœ¨ã™ã‚‹QA_IDãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å­˜åœ¨ã™ã‚‹ã‹
2. ignoreãƒªã‚¹ãƒˆã®æ•´åˆæ€§
3. ãƒ™ã‚¯ãƒˆãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å†æ§‹ç¯‰æ–¹æ³•ã®è¡¨ç¤º
"""

import os
import sys
import pickle
import json
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent / "app"))

from database_utils import get_db_cursor, get_placeholder


VECTOR_DIR = Path("./app/api/utils/vectors")


def load_vector_meta(lang_code):
    """æŒ‡å®šè¨€èªã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    meta_path = VECTOR_DIR / f"vectors_{lang_code}.meta.pkl"
    if not meta_path.exists():
        return None
    
    with open(meta_path, "rb") as f:
        return pickle.load(f)


def load_vector_texts(lang_code):
    """æŒ‡å®šè¨€èªã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    texts_path = VECTOR_DIR / f"vectors_{lang_code}.texts.pkl"
    if not texts_path.exists():
        return None
    
    with open(texts_path, "rb") as f:
        return pickle.load(f)


def load_ignore_qa_ids():
    """ç„¡è¦–ã•ã‚Œã‚‹QA_IDã®ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿"""
    ignore_path = VECTOR_DIR / "vectors_ignore_qa.json"
    if not ignore_path.exists():
        return set()
    
    with open(ignore_path, "r", encoding="utf-8") as f:
        return set(json.load(f))


def load_ignore_hashes(lang_code):
    """æŒ‡å®šè¨€èªã®ç„¡è¦–ãƒãƒƒã‚·ãƒ¥ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿"""
    hash_path = VECTOR_DIR / f"vectors_{lang_code}.ignore_hash.json"
    if not hash_path.exists():
        return set()
    
    with open(hash_path, "r", encoding="utf-8") as f:
        return set(json.load(f))


def get_all_qa_ids_from_db():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å…¨ã¦ã®QA_IDã‚’å–å¾—"""
    with get_db_cursor() as (cursor, conn):
        cursor.execute("SELECT id, question_id, answer_id FROM QA")
        rows = cursor.fetchall()
        return {row['id']: (row['question_id'], row['answer_id']) for row in rows}


def verify_language_vectors(lang_code, db_qa_ids, ignored_qa_ids):
    """ç‰¹å®šè¨€èªã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¤œè¨¼"""
    print(f"\n{'='*60}")
    print(f"è¨€èª: {lang_code.upper()}")
    print(f"{'='*60}")
    
    meta = load_vector_meta(lang_code)
    texts = load_vector_texts(lang_code)
    ignore_hashes = load_ignore_hashes(lang_code)
    
    if meta is None:
        print(f"âš ï¸  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    if texts is None:
        print(f"âš ï¸  ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"ãƒ™ã‚¯ãƒˆãƒ«ç·æ•°: {len(meta)}")
    print(f"ç„¡è¦–ãƒãƒƒã‚·ãƒ¥æ•°: {len(ignore_hashes)}")
    
    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å­˜åœ¨ã™ã‚‹ãŒã€DBã«å­˜åœ¨ã—ãªã„QAã‚’æ¤œå‡º
    orphaned_vectors = []
    
    for idx, (qa_id, question_id) in enumerate(meta):
        if qa_id is None:
            continue
            
        # DBã«å­˜åœ¨ã—ãªã„QA_ID
        if qa_id not in db_qa_ids:
            # ç„¡è¦–ãƒªã‚¹ãƒˆã«ã‚‚å«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯å•é¡Œ
            if qa_id not in ignored_qa_ids:
                question_text, answer_text, time_val = texts[idx] if idx < len(texts) else ("N/A", "N/A", None)
                orphaned_vectors.append({
                    'idx': idx,
                    'qa_id': qa_id,
                    'question_id': question_id,
                    'question_text': question_text[:50] + '...' if len(question_text) > 50 else question_text,
                    'answer_text': answer_text[:50] + '...' if len(answer_text) > 50 else answer_text,
                })
    
    if orphaned_vectors:
        print(f"\nâš ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å­˜åœ¨ã—ãªã„QAãŒãƒ™ã‚¯ãƒˆãƒ«ã« {len(orphaned_vectors)} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
        for v in orphaned_vectors[:10]:  # æœ€åˆã®10ä»¶ã‚’è¡¨ç¤º
            print(f"  - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {v['idx']}, QA_ID: {v['qa_id']}, Question: {v['question_text']}")
        
        if len(orphaned_vectors) > 10:
            print(f"  ... ä»– {len(orphaned_vectors) - 10} ä»¶")
    else:
        print(f"âœ… å…¨ã¦ã®ãƒ™ã‚¯ãƒˆãƒ«ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨æ•´åˆã—ã¦ã„ã¾ã™")


def main():
    print("=" * 60)
    print("ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆæ€§æ¤œè¨¼")
    print("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å…¨QA_IDã‚’å–å¾—
    print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ QA ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    db_qa_ids = get_all_qa_ids_from_db()
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®QAç·æ•°: {len(db_qa_ids)}")
    
    # ç„¡è¦–ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
    ignored_qa_ids = load_ignore_qa_ids()
    print(f"ç„¡è¦–ãƒªã‚¹ãƒˆå†…ã®QA_IDæ•°: {len(ignored_qa_ids)}")
    
    # å„è¨€èªã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ¤œè¨¼
    languages = ['ja', 'en', 'vi', 'zh', 'ko', 'pt', 'es', 'tl', 'id']
    
    for lang in languages:
        verify_language_vectors(lang, db_qa_ids, ignored_qa_ids)
    
    print("\n" + "=" * 60)
    print("ãƒ™ã‚¯ãƒˆãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å†æ§‹ç¯‰æ–¹æ³•")
    print("=" * 60)
    print("""
1. å®Œå…¨å†æ§‹ç¯‰ï¼ˆæ¨å¥¨ï¼‰:
   Pythonã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚·ã‚§ãƒ«ã‹ã‚‰:
   
   >>> from app.api.utils.RAG import generate_and_save_vectors
   >>> generate_and_save_vectors()
   
   ã¾ãŸã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ç›´æ¥å®Ÿè¡Œ:
   
   python3 -c "import sys; sys.path.insert(0, 'app'); from api.utils.RAG import generate_and_save_vectors; generate_and_save_vectors()"

2. æ—¢å­˜ãƒ™ã‚¯ãƒˆãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—:
   
   cp -r app/api/utils/vectors app/api/utils/vectors_backup_$(date +%Y%m%d_%H%M%S)

3. ãƒ™ã‚¯ãƒˆãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ï¼ˆå†æ§‹ç¯‰å‰ï¼‰:
   
   rm -f app/api/utils/vectors/*.faiss
   rm -f app/api/utils/vectors/*.pkl
   rm -f app/api/utils/vectors/*.json

æ³¨æ„: 
- generate_and_save_vectors() ã¯å…¨ã¦ã®QAãƒšã‚¢ã‚’å†å‡¦ç†ã—ã€æ–°ã—ã„ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã™
- å‡¦ç†ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼ˆQAã®æ•°ã«ä¾å­˜ï¼‰
- å‡¦ç†ä¸­ã¯OpenAI APIãŒå‘¼ã³å‡ºã•ã‚Œã‚‹ãŸã‚ã€APIä½¿ç”¨æ–™ãŒç™ºç”Ÿã—ã¾ã™
""")


if __name__ == "__main__":
    main()
