#!/usr/bin/env python3
"""
ãƒ™ã‚¯ãƒˆãƒ«ã¨DBã®æ•´åˆæ€§ã‚’è©³ç´°ã«æ¤œè¨¼
"""

import sys
import pickle
import json
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent / "app"))

try:
    from database_utils import get_db_cursor
    
    VECTOR_DIR = Path("./app/api/utils/vectors")
    
    def main():
        print("=" * 80)
        print("ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ•´åˆæ€§æ¤œè¨¼")
        print("=" * 80)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å…¨QA_IDã‚’å–å¾—
        print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰QAãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        with get_db_cursor() as (cursor, conn):
            cursor.execute("SELECT id, question_id, answer_id FROM QA")
            rows = cursor.fetchall()
            db_qa_ids = {row['id']: (row['question_id'], row['answer_id']) for row in rows}
        
        print(f"âœ“ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®QAç·æ•°: {len(db_qa_ids)}")
        print(f"âœ“ QA_IDç¯„å›²: {min(db_qa_ids.keys()) if db_qa_ids else 'N/A'} - {max(db_qa_ids.keys()) if db_qa_ids else 'N/A'}")
        
        # ç„¡è¦–ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
        ignore_path = VECTOR_DIR / "vectors_ignore_qa.json"
        ignored_qa_ids = set()
        if ignore_path.exists():
            with open(ignore_path, "r", encoding="utf-8") as f:
                ignored_qa_ids = set(json.load(f))
        
        print(f"âœ“ ç„¡è¦–ãƒªã‚¹ãƒˆå†…ã®QA_IDæ•°: {len(ignored_qa_ids)}")
        
        languages = ['ja', 'en', 'vi', 'zh', 'ko', 'pt', 'es', 'tl', 'id']
        
        all_orphaned = {}
        
        for lang in languages:
            meta_path = VECTOR_DIR / f"vectors_{lang}.meta.pkl"
            texts_path = VECTOR_DIR / f"vectors_{lang}.texts.pkl"
            hash_path = VECTOR_DIR / f"vectors_{lang}.ignore_hash.json"
            
            if not meta_path.exists():
                continue
            
            with open(meta_path, "rb") as f:
                meta = pickle.load(f)
            
            with open(texts_path, "rb") as f:
                texts = pickle.load(f)
            
            ignore_hashes = set()
            if hash_path.exists():
                with open(hash_path, "r", encoding="utf-8") as f:
                    ignore_hashes = set(json.load(f))
            
            orphaned_vectors = []
            
            for idx, (qa_id, question_id) in enumerate(meta):
                if qa_id is None:
                    continue
                
                # DBã«å­˜åœ¨ã—ãªã„QA_ID
                if qa_id not in db_qa_ids:
                    # ç„¡è¦–ãƒªã‚¹ãƒˆã«ã‚‚å«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯å•é¡Œ
                    if qa_id not in ignored_qa_ids:
                        question_text, answer_text, time_val = texts[idx] if idx < len(texts) else ("N/A", "N/A", None)
                        orphaned_vectors.append({
                            'idx': idx,
                            'qa_id': qa_id,
                            'question_id': question_id,
                            'question': question_text[:80] + '...' if len(question_text) > 80 else question_text,
                            'answer': answer_text[:80] + '...' if len(answer_text) > 80 else answer_text,
                        })
            
            if orphaned_vectors:
                all_orphaned[lang] = orphaned_vectors
        
        # çµæœè¡¨ç¤º
        print("\n" + "=" * 80)
        print("æ¤œè¨¼çµæœ")
        print("=" * 80)
        
        if all_orphaned:
            print("\nâš ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å­˜åœ¨ã—ãªã„QAãŒãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:\n")
            
            for lang, orphaned in all_orphaned.items():
                print(f"\nã€{lang.upper()}ã€‘: {len(orphaned)} ä»¶ã®å­¤ç«‹ãƒ™ã‚¯ãƒˆãƒ«")
                print("-" * 80)
                
                for v in orphaned[:5]:  # æœ€åˆã®5ä»¶ã‚’è¡¨ç¤º
                    print(f"  QA_ID: {v['qa_id']}")
                    print(f"    Q: {v['question']}")
                    print(f"    A: {v['answer']}")
                    print()
                
                if len(orphaned) > 5:
                    print(f"  ... ä»– {len(orphaned) - 5} ä»¶\n")
            
            print("\n" + "=" * 80)
            print("âš ï¸  å•é¡Œã®åŸå› :")
            print("=" * 80)
            print("""
1. QAãŒå‰Šé™¤ã•ã‚ŒãŸãŒã€ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰å‰Šé™¤ã•ã‚Œã¦ã„ãªã„
2. ignoreæ©Ÿèƒ½ãŒæ­£ã—ãå‹•ä½œã—ã¦ã„ãªã„å¯èƒ½æ€§
3. ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨DBã®åŒæœŸãŒå–ã‚Œã¦ã„ãªã„

æ¨å¥¨ã•ã‚Œã‚‹å¯¾å‡¦æ³•:
1. ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å®Œå…¨å†æ§‹ç¯‰
2. ignoreæ©Ÿèƒ½ã®è¦‹ç›´ã—
""")
        else:
            print("\nâœ… å…¨ã¦ã®è¨€èªã§ã€ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯æ•´åˆã—ã¦ã„ã¾ã™")
        
        print("\n" + "=" * 80)
        print("ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å†æ§‹ç¯‰æ–¹æ³•")
        print("=" * 80)
        print("""
ã€æ–¹æ³•1ã€‘å®Œå…¨å†æ§‹ç¯‰ï¼ˆæ¨å¥¨ï¼‰
--------------------------------------------------
Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§ä»¥ä¸‹ã‚’å®Ÿè¡Œ:

docker exec -it shigachat-app-1 python3 -c "
import sys
sys.path.insert(0, '/app')
from api.utils.RAG import generate_and_save_vectors
generate_and_save_vectors()
"

ã€æ–¹æ³•2ã€‘Pythonã‚·ã‚§ãƒ«ã‹ã‚‰å®Ÿè¡Œ
--------------------------------------------------
docker exec -it shigachat-app-1 python3

>>> import sys
>>> sys.path.insert(0, '/app')
>>> from api.utils.RAG import generate_and_save_vectors
>>> generate_and_save_vectors()

ã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆæ¨å¥¨ï¼‰ã€‘
--------------------------------------------------
å†æ§‹ç¯‰å‰ã«ãƒ™ã‚¯ãƒˆãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—:

docker exec shigachat-app-1 sh -c "
    cd /app/api/utils &&
    tar czf vectors_backup_$(date +%Y%m%d_%H%M%S).tar.gz vectors/
"

ã€æ³¨æ„äº‹é …ã€‘
--------------------------------------------------
- å‡¦ç†ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼ˆQAæ•°ã«ä¾å­˜ï¼‰
- OpenAI APIãŒå‘¼ã³å‡ºã•ã‚Œã‚‹ãŸã‚ã€APIä½¿ç”¨æ–™ãŒç™ºç”Ÿã—ã¾ã™
- å‡¦ç†ä¸­ã¯ã‚µãƒ¼ãƒ“ã‚¹ã®å¿œç­”ãŒé…ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
""")
        
except Exception as e:
    print(f"ã‚¨ãƒ©ãƒ¼: {e}")
    import traceback
    traceback.print_exc()


if __name__ == "__main__":
    main()
